<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"gjq-666.github.io","root":"/","scheme":"Muse","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Apache Kafka一、概述Apache Kafka是一个分布式的流数据平台，代表三层含义：  Publish&#x2F;Subscribe: 消息队列系统 MQ（Message Queue） Process: 流数据的实时处理（Stream Process） Store: 流数据会以一种安全、容错冗余存储机制存放到分布式集群中  架构 应用场景 构建实时的流数据管道，在系统和应用之间进行可靠的流数据传">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka.md">
<meta property="og:url" content="https://gjq-666.github.io/2020/02/26/Kafka-md/index.html">
<meta property="og:site_name" content="welcome gjq-666">
<meta property="og:description" content="Apache Kafka一、概述Apache Kafka是一个分布式的流数据平台，代表三层含义：  Publish&#x2F;Subscribe: 消息队列系统 MQ（Message Queue） Process: 流数据的实时处理（Stream Process） Store: 流数据会以一种安全、容错冗余存储机制存放到分布式集群中  架构 应用场景 构建实时的流数据管道，在系统和应用之间进行可靠的流数据传">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/1570779395086.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/log_anatomy.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/log_consumer-1570781067075.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/1570787863465.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1570852913358.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571036808522.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/20190830063445252.gif">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/aHR0cHM6Ly9hc2sucWNsb3VkaW1nLmNvbS9odHRwLXNhdmUvZGV2ZWxvcGVyLW5ld3MvdjZiZjhxZ3B3dC5qcGVn.jpg">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/20190830064713109.gif">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/aHR0cHM6Ly9hc2sucWNsb3VkaW1nLmNvbS9odHRwLXNhdmUvZGV2ZWxvcGVyLW5ld3MvcWg4dGZlYjlwNC5qcGVn.jpg">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571122121002.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571122141260.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571122150248.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571130666409.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/963903-20180823012822162-142241598.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571211039841.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-stateful_operations.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-time-windows-tumbling-1571297999267.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/963903-20180823013225516-1830552448-1571297996894.gif">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-time-windows-hopping-1571297998866.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/963903-20180823013127357-1860834711-1571297996613.gif">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-session-windows-01-1571297997083.png">
<meta property="og:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-session-windows-02-1571297997111.png">
<meta property="article:published_time" content="2020-02-26T06:28:42.000Z">
<meta property="article:modified_time" content="2020-02-26T09:00:01.772Z">
<meta property="article:author" content="骚白">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gjq-666.github.io/2020/02/26/Kafka-md/1570779395086.png">

<link rel="canonical" href="https://gjq-666.github.io/2020/02/26/Kafka-md/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Kafka.md | welcome gjq-666</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">welcome gjq-666</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://gjq-666.github.io/2020/02/26/Kafka-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="骚白">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="welcome gjq-666">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka.md
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-02-26 14:28:42 / Modified: 17:00:01" itemprop="dateCreated datePublished" datetime="2020-02-26T14:28:42+08:00">2020-02-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Apache-Kafka"><a href="#Apache-Kafka" class="headerlink" title="Apache Kafka"></a>Apache Kafka</h1><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>Apache Kafka是一个分布式的流数据平台，代表三层含义：</p>
<ul>
<li><strong>Publish/Subscribe</strong>: 消息队列系统 MQ（Message Queue）</li>
<li><strong>Process</strong>: 流数据的实时处理（Stream Process）</li>
<li><strong>Store</strong>: 流数据会以一种安全、容错冗余存储机制存放到分布式集群中</li>
</ul>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/2020/02/26/Kafka-md/1570779395086.png" alt="1570779395086"></p>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul>
<li>构建实时的流数据管道，在系统和应用之间进行可靠的流数据传输</li>
<li>构建实时的流数据处理应用，对流数据进行转换和加工处理</li>
</ul>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ul>
<li><code>Cluster</code>： kafka支持一到多个服务构成的分布式集群，每一个服务实例成为<code>Broker</code></li>
<li><code>Topic</code>:  某一个分类的消息的集合，如：订单的topic、商品的topic等</li>
<li><code>Partition</code>: 一个Topic有若干个分区（Partition）构成，分区的数量在创建Topic时手动指定</li>
<li><code>Replication</code>:  分区副本，是Partition的冗余备份分区，当Partition不可用时，ZooKeeper会自动将Replication（Follower）分区升级为Partition（Leader）分区</li>
<li><code>Offset</code>:  分区中的Record的位置标示，每一个消费者都会记录自己的消费位置（offset）</li>
</ul>
<h3 id="Topic和Log"><a href="#Topic和Log" class="headerlink" title="Topic和Log"></a>Topic和Log</h3><blockquote>
<p>Each partition is an ordered, immutable sequence of records that is continually appended to—a structured commit log</p>
<p>Kafka的每一个分区（Partition），都是一个有序、不可变的持续追加的记录序列，Kafka会以一种结构化的提交日志保存分区中的数据。</p>
</blockquote>
<p><img src="/2020/02/26/Kafka-md/log_anatomy.png" alt="log_anatomy"></p>
<blockquote>
<p>注意：在分区中写入数据时，会在队列的末尾进行追加，每一个消费者都维护的有一个自己的消费位置（offset）</p>
</blockquote>
<p><img src="/2020/02/26/Kafka-md/log_consumer-1570781067075.png" alt="img"></p>
<h2 id="二、环境搭建"><a href="#二、环境搭建" class="headerlink" title="二、环境搭建"></a>二、环境搭建</h2><blockquote>
<p>完全分布式的Kafka集群</p>
</blockquote>
<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ul>
<li><p>分布式集群中时钟同步</p>
</li>
<li><p>JDK1.8以上</p>
</li>
<li><p>ZooKeeper集群服务运行正常</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode0* zookeeper-3.4.6]# vi conf/zoo.cfg</span><br><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/home/zk/data</span><br><span class="line">clientPort=2181</span><br><span class="line">server.1=hadoopnode01:2887:3887</span><br><span class="line">server.2=hadoopnode02:2888:3888</span><br><span class="line">server.3=hadoopnode03:2889:3889</span><br><span class="line"></span><br><span class="line">[root@HadoopNode0* zookeeper-3.4.6]# cd /home/zk</span><br><span class="line">[root@HadoopNode0* zk]# mkdir data</span><br><span class="line">[root@HadoopNode0* zk]# vi data/myid</span><br><span class="line"><span class="meta">#</span><span class="bash"> Node01</span></span><br><span class="line">1</span><br><span class="line"><span class="meta">#</span><span class="bash"> Node02</span></span><br><span class="line">2</span><br><span class="line"><span class="meta">#</span><span class="bash"> Node03</span></span><br><span class="line">3</span><br><span class="line">[root@HadoopNode0* zookeeper-3.4.6]# bin/zkServer.sh start conf/zoo.cfg</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如何判断zookeeper集群服务正常</span></span><br><span class="line">[root@HadoopNode03 zookeeper-3.4.6]# bin/zkServer.sh status conf/zoo.cfg</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: conf/zoo.cfg</span><br><span class="line">Mode: leader  (一主两从)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h3><ul>
<li><p>将安装包上传并复制到其它节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 上传到某一个服务器，并拷贝给其它服务器</span></span><br><span class="line"></span><br><span class="line">[root@HadoopNode01 ~]# scp kafka_2.11-2.2.0.tgz root@hadoopnode02:~</span><br><span class="line">kafka_2.11-2.2.0.tgz                                                                         100%   61MB  61.0MB/s   00:00</span><br><span class="line">[root@HadoopNode01 ~]# scp kafka_2.11-2.2.0.tgz root@hadoopnode03:~</span><br><span class="line">kafka_2.11-2.2.0.tgz</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装Kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode0* ~]# tar -zxf kafka_2.11-2.2.0.tgz -C /usr</span><br><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]# ll</span><br><span class="line">total 52</span><br><span class="line">drwxr-xr-x. 3 root root  4096 Mar 10  2019 bin  # 指令</span><br><span class="line">drwxr-xr-x. 2 root root  4096 Mar 10  2019 config  # 配置文件</span><br><span class="line">drwxr-xr-x. 2 root root  4096 Oct  9 08:56 libs  # 依赖jar包</span><br><span class="line">-rw-r--r--. 1 root root 32216 Mar 10  2019 LICENSE </span><br><span class="line">-rw-r--r--. 1 root root   336 Mar 10  2019 NOTICE </span><br><span class="line">drwxr-xr-x. 2 root root  4096 Mar 10  2019 site-docs  # 使用文档</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><ul>
<li><p>修改kafka核心配置文件<code>server.properties</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]# vi config/server.properties</span><br><span class="line">broker.id=0 | 1 | 2</span><br><span class="line">listeners=PLAINTEXT://HadoopNode0[1 | 2 | 3]:9092</span><br><span class="line">log.dirs=/usr/kafka_2.11-2.2.0/data</span><br><span class="line">zookeeper.connect=HadoopNode01:2181,HadoopNode02:2181,HadoopNode03:2181</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><ul>
<li><p>启动</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">[root@HadoopNode0*</span> <span class="string">kafka_2.11-2.2.0]# bin/kafka-server-start.sh -daemon config/server.properties</span></span><br><span class="line"><span class="meta">[root@HadoopNode0*</span> <span class="string">kafka_2.11-2.2.0]# jps</span></span><br><span class="line"><span class="attr">10386</span> <span class="string">Kafka</span></span><br><span class="line"><span class="attr">10517</span> <span class="string">Jps</span></span><br><span class="line"><span class="attr">3276</span> <span class="string">QuorumPeerMain</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode0* kafka_2.11-2.2.0]# bin/kafka-server-stop.sh config/server.properties</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h2 id="三、基础使用"><a href="#三、基础使用" class="headerlink" title="三、基础使用"></a>三、基础使用</h2><h3 id="命令行操作"><a href="#命令行操作" class="headerlink" title="命令行操作"></a>命令行操作</h3><h4 id="Topic使用"><a href="#Topic使用" class="headerlink" title="Topic使用"></a>Topic使用</h4><ul>
<li><p>新建Topic</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">[root@HadoopNode01</span> <span class="string">kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server Zk01:9092,Zk02:9092,Zk03:9092 --topic t1 --partitions 3 --replication-factor 3 --create</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>展示Topic列表</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server Zk01:9092,Zk02:9092,Zk03:9092  --list</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除Topic</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">[root@HadoopNode02</span> <span class="string">kafka_2.11-2.2.0]#  bin/kafka-topics.sh --bootstrap-server Zk01:9092,Zk02:9092,Zk03:9092  --delete --topic baizhi</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>描述Topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode02 kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092  --describe --topic t1</span><br><span class="line">Topic:t1        PartitionCount:3        ReplicationFactor:3     Configs:segment.bytes=1073741824</span><br><span class="line">        Topic: t1       Partition: 0    Leader: 0       Replicas: 0,2,1 Isr: 0,2,1</span><br><span class="line">        Topic: t1       Partition: 1    Leader: 2       Replicas: 2,1,0 Isr: 2,1,0</span><br><span class="line">        Topic: t1       Partition: 2    Leader: 1       Replicas: 1,0,2 Isr: 1,0,2</span><br><span class="line">        </span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试：<span class="built_in">kill</span>掉Node03上的kafka服务实例  也就是broker【2】</span></span><br><span class="line">[root@HadoopNode02 kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092  --describe --topic t1</span><br><span class="line">Topic:t1        PartitionCount:3        ReplicationFactor:3     Configs:segment.bytes=1073741824</span><br><span class="line">        Topic: t1       Partition: 0    Leader: 0       Replicas: 0,2,1 Isr: 0,1</span><br><span class="line">        Topic: t1       Partition: 1    Leader: 1       Replicas: 2,1,0 Isr: 1,0</span><br><span class="line">        Topic: t1       Partition: 2    Leader: 1       Replicas: 1,0,2 Isr: 1,0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试：恢复运行Node03上的Kafka服务实例Broker[2]，第三列信息不改变的原因：（分区的Leader都存在，不会触发ZK的故障转移），第五列信息不变</span></span><br><span class="line">[root@HadoopNode02 kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092  --describe --topic t1</span><br><span class="line">Topic:t1        PartitionCount:3        ReplicationFactor:3     Configs:segment.bytes=1073741824</span><br><span class="line">        Topic: t1       Partition: 0    Leader: 0       Replicas: 0,2,1 Isr: 0,1,2</span><br><span class="line">        Topic: t1       Partition: 1    Leader: 1       Replicas: 2,1,0 Isr: 1,0,2</span><br><span class="line">        Topic: t1       Partition: 2    Leader: 1       Replicas: 1,0,2 Isr: 1,0,2</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/26/Kafka-md/1570787863465.png" alt="1570787863465"></p>
</li>
</ul>
<ul>
<li><p>修改Topic</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">[root@HadoopNode02</span> <span class="string">kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092  --alter --topic t1 --partitions 5</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="发布和订阅"><a href="#发布和订阅" class="headerlink" title="发布和订阅"></a>发布和订阅</h4><ul>
<li><p>发布消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]# bin/kafka-console-producer.sh --broker-list Zk01:9092,Zk02:9092,Zk03:9092 --topic t1</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">Hello World</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">Hello Kafka</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">Hello Hadoop</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>订阅消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode02 kafka_2.11-2.2.0]# bin/kafka-console-consumer.sh --topic t1 --bootstrap-server Zk01:9092,Zk02:9092,Zk03:9092</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h3 id="JAVA-Driver"><a href="#JAVA-Driver" class="headerlink" title="JAVA Driver"></a>JAVA Driver</h3><h4 id="Maven依赖"><a href="#Maven依赖" class="headerlink" title="Maven依赖"></a>Maven依赖</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="准备工作-1"><a href="#准备工作-1" class="headerlink" title="准备工作"></a>准备工作</h4><ul>
<li><p>配置Windows Hosts主机名和IP映射</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">192.168.11.20 HadoopNode00</span><br><span class="line">192.168.11.21 HadoopNode01</span><br><span class="line">192.168.11.22 HadoopNode02</span><br><span class="line">192.168.11.23 HadoopNode03</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kafka 生产者的测试类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 准备Kafka生产者配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        <span class="comment">// string 序列化（Object ---&gt; byte[]）器</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 生产记录并将其发布</span></span><br><span class="line">        ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"t2"</span>, UUID.randomUUID().toString(),<span class="string">"Hello Kafka"</span>);</span><br><span class="line"></span><br><span class="line">        producer.send(record);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 释放资源</span></span><br><span class="line">        producer.flush();</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>1） Kafka的消息生产者，负责生产数据（Record K\V\Timestamp），最终发布（Publish）保存到Kafka集群</p>
<p>2）数据的保存策略：</p>
<ul>
<li>如果Record的Key不为<code>Null</code>，采用哈希算法：<code>key.hashCode % numPartitions = 余数（分区序号）</code></li>
<li>如果Record的Key为<code>Null</code>, 采用轮询策略</li>
<li>手动指定存放的分区</li>
</ul>
<p>3） 数据会以一种分布式的方式保存在Kafka集群中，每一个分区都会维护一个队列的数据结构，新产生的数据会追加到队列的末尾，并且分配<code>offset</code>, </p>
<p>4）数据在Kafka集群中默认最多保留7天（168Hours），不论是否消费，在保留周期到达后都会自动被删除。</p>
<p>5）数据在Kafka中可以进行重复消费，重置消费offset即可</p>
</blockquote>
<h4 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kafka消费者测试类</span></span><br><span class="line"><span class="comment"> * 1. 订阅 subscribe</span></span><br><span class="line"><span class="comment"> * 2. 拉取 pull</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 指定kafka消费者的配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        <span class="comment">// 反序列化器 byte[] ---&gt; Object</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="comment">// 消费组必须得指定</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"group1"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建kafka消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 订阅主体topic</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"t2"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 拉取新产生的记录</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">10</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.println(record.key() + <span class="string">"\t"</span> + record.value() + <span class="string">"\t"</span></span><br><span class="line">                        + record.topic() + <span class="string">"\t"</span> + record.offset()</span><br><span class="line">                        + <span class="string">"\t"</span> + record.timestamp() + <span class="string">"\t"</span> + record.partition());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1570852913358.png" alt="1570852913358"></p>
<blockquote>
<p>1）消费者并不是独立存在，kafka中消费者会以消费组的方式进行组织和管理</p>
<p>2）<strong>消费组符合特征： 组外广播、组内负载均衡</strong></p>
<ul>
<li>组外广播： 保证不同的消费组，能够独立消费新产生的数据</li>
<li>组内负载均衡： 消息只会被消费组中的一个消费着进行处理，多个消费组提高了Kafka并行处理能力</li>
</ul>
<p>3）消费者可以订阅一个到多个感兴趣的Topic，一旦这些Topic有新的数据产生，消费者会自动拉取新产生的数据，进行相应的业务处理</p>
<p>4）消费者在消费消息时，会维护一个消费的位置（offset），下一次消费时会自动从offset向后进行消费。</p>
<p>​      在kafka中数据会有一个默认的保留周期（7天），在保留期内数据是可以进行重复消费的，只需要重置消费者消费的offset即可。</p>
<p>5）<code>__consumer_offsets</code>是一个特殊topic，主要记录了Kafka消费组的消费位置。</p>
</blockquote>
<h2 id="四、高级部分"><a href="#四、高级部分" class="headerlink" title="四、高级部分"></a>四、高级部分</h2><h3 id="偏移量控制"><a href="#偏移量控制" class="headerlink" title="偏移量控制"></a>偏移量控制</h3><p>Kafka消费者在订阅Topic时，会自动拉取Topic中新产生的数据。首次消费时使用默认的偏移量消费策略==lastest==</p>
<p>偏移量消费策略：</p>
<ul>
<li><p>==lastest（默认）==：如果有已提交的offset，从已提交的offset之后消费消息。如果无提交的offset，从最后的offset之后消费数据</p>
</li>
<li><p>==earliest==：如果有已提交的offset，从已提交的offset之后消费消息。如果无提交的offset，从最早的offset消费消息</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注意：此配置项 修改偏移量消费策略的默认行为 </span></span><br><span class="line">properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,<span class="string">"earliest"</span>);</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>Kafka消费者消费位置offset，默认采用自动提交的方式，将消费位置提交保存到特殊Topic<code>__consumer_offsets</code>中</p>
<p>自动提交策略：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 默认自动提交消费的位置offset</span></span><br><span class="line">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,<span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 默认每隔5秒提交一次消费位置</span></span><br><span class="line">properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG,<span class="number">5000</span>);</span><br></pre></td></tr></table></figure>

<p>通常情况需要手动提交消费位置：</p>
<blockquote>
<p>为什么需要手动提交消费位置（offset）的原因？</p>
<p>原因：如果自动提交消费位置，有可能在进行业务处理时出现错误，会造成数据没有被正确处理。</p>
<p>​            手动提交消费位置，可以保证数据一定能够被完整的正确处理。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 关闭消费位置offset的自动提交功能</span></span><br><span class="line">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 手动提交消费位置</span></span><br><span class="line">consumer.commitSync();</span><br></pre></td></tr></table></figure>

<h3 id="消费方式"><a href="#消费方式" class="headerlink" title="消费方式"></a>消费方式</h3><h4 id="订阅（Subscribe）"><a href="#订阅（Subscribe）" class="headerlink" title="订阅（Subscribe）"></a>订阅（Subscribe）</h4><blockquote>
<p>消费者订阅1到N个感兴趣的Topic，一旦Topic中有新的数据产生，会自动拉取Topic分区内的所有数据</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 订阅（消费）Topic所有的分区</span></span><br><span class="line">consumer.subscribe(Arrays.asList(<span class="string">"t3"</span>));</span><br></pre></td></tr></table></figure>

<h4 id="指定消费分区"><a href="#指定消费分区" class="headerlink" title="指定消费分区"></a>指定消费分区</h4><blockquote>
<p>消费者在消费数据时，可以只消费某个Topic特定分区内的数据</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定消费Topic的特定分区</span></span><br><span class="line">consumer.assign(Arrays.asList(<span class="keyword">new</span> TopicPartition(<span class="string">"t3"</span>,<span class="number">0</span>)));</span><br></pre></td></tr></table></figure>

<h4 id="重置消费位置"><a href="#重置消费位置" class="headerlink" title="重置消费位置"></a>重置消费位置</h4><blockquote>
<p>消费者在消费数据时，可以重置消费的offset，消费已消费的数据或者跳过不感兴趣的数据</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">consumer.assign(Arrays.asList(<span class="keyword">new</span> TopicPartition(<span class="string">"t3"</span>,<span class="number">0</span>)));</span><br><span class="line"><span class="comment">// 重置消费位置</span></span><br><span class="line">consumer.seek(<span class="keyword">new</span> TopicPartition(<span class="string">"t3"</span>,<span class="number">0</span>),<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<h3 id="消费组"><a href="#消费组" class="headerlink" title="消费组"></a>消费组</h3><p>（略）</p>
<h3 id="自定义对象类型的传输"><a href="#自定义对象类型的传输" class="headerlink" title="自定义对象类型的传输"></a>自定义对象类型的传输</h3><h4 id="序列化接口"><a href="#序列化接口" class="headerlink" title="序列化接口"></a>序列化接口</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Serializer</span>&lt;<span class="title">T</span>&gt; <span class="keyword">extends</span> <span class="title">Closeable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; var1, <span class="keyword">boolean</span> var2)</span></span>;</span><br><span class="line">	<span class="comment">// 序列化方法</span></span><br><span class="line">    <span class="keyword">byte</span>[] serialize(String var1, T var2);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">default</span> <span class="keyword">byte</span>[] serialize(String topic, Headers headers, T data) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.serialize(topic, data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>发序列化接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Deserializer</span>&lt;<span class="title">T</span>&gt; <span class="keyword">extends</span> <span class="title">Closeable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; var1, <span class="keyword">boolean</span> var2)</span></span>;</span><br><span class="line">	</span><br><span class="line">    <span class="comment">// 反序列化方法</span></span><br><span class="line">    <span class="function">T <span class="title">deserialize</span><span class="params">(String var1, <span class="keyword">byte</span>[] var2)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">default</span> T <span class="title">deserialize</span><span class="params">(String topic, Headers headers, <span class="keyword">byte</span>[] data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.deserialize(topic, data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="自定义对象"><a href="#自定义对象" class="headerlink" title="自定义对象"></a>自定义对象</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Integer id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> Date birthday;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="导入工具包的依赖jar包"><a href="#导入工具包的依赖jar包" class="headerlink" title="导入工具包的依赖jar包"></a>导入工具包的依赖jar包</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-lang<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="自定义编解码器类"><a href="#自定义编解码器类" class="headerlink" title="自定义编解码器类"></a>自定义编解码器类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> transfer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.SerializationUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.Deserializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.Serializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义对象的编解码器类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ObjectCodec</span> <span class="keyword">implements</span> <span class="title">Serializer</span>, <span class="title">Deserializer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * bytes[] ---&gt; Object</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> s</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> bytes</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">deserialize</span><span class="params">(String s, <span class="keyword">byte</span>[] bytes)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> SerializationUtils.deserialize(bytes);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map map, <span class="keyword">boolean</span> b)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Object ---&gt; bytes[]</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> s</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> o</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(String s, Object o) &#123;</span><br><span class="line">        <span class="keyword">return</span> SerializationUtils.serialize((Serializable) o);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><blockquote>
<p>建议新创建Topic进行测试，避免旧的Topic中历史数据对我们产生干扰</p>
</blockquote>
<h5 id="生产者API"><a href="#生产者API" class="headerlink" title="生产者API"></a>生产者API</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> transfer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kafka 生产者的测试类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 准备Kafka生产者配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        <span class="comment">// string 序列化（Object ---&gt; byte[]）器</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,ObjectCodec<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, User&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, User&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 生产记录并将其发布</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="comment">// key不为null  第一种策略</span></span><br><span class="line">            ProducerRecord&lt;String, User&gt; record = <span class="keyword">new</span> ProducerRecord&lt;String, User&gt;(<span class="string">"t4"</span>, UUID.randomUUID().toString(),</span><br><span class="line">                    <span class="keyword">new</span> User(i,<span class="string">"zs:"</span>+i,<span class="keyword">new</span> Date()));</span><br><span class="line">            <span class="comment">// key为null 轮询策略</span></span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 释放资源</span></span><br><span class="line">        producer.flush();</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="消费者API"><a href="#消费者API" class="headerlink" title="消费者API"></a>消费者API</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> transfer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kafka消费者测试类</span></span><br><span class="line"><span class="comment"> * 1. 订阅 subscribe</span></span><br><span class="line"><span class="comment"> * 2. 拉取 pull</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//1. 指定kafka消费者的配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        <span class="comment">// 反序列化器 byte[] ---&gt; Object</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ObjectCodec<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="comment">// 注意：此配置项 修改偏移量消费策略的默认行为</span></span><br><span class="line">        properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关闭消费位置offset的自动提交功能</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">//properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG,5000);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 消费组必须得指定</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"group1"</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建kafka消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, User&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, User&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 订阅主体topic</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"t4"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 拉取新产生的记录</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, User&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">10</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, User&gt; record : records) &#123;</span><br><span class="line">                User user = record.value();</span><br><span class="line">                System.out.println(user);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 手动提交消费位置</span></span><br><span class="line">            consumer.commitSync();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="生产者的批量发送"><a href="#生产者的批量发送" class="headerlink" title="生产者的批量发送"></a>生产者的批量发送</h3><blockquote>
<p>kafka生产者产生的多条数据共享同一个连接，发送保存到Kafka集群，这种操作方式称为：==Batch（批处理）==。</p>
<p>批处理相比于传统的发送方式，资源利用率更为高效，是一种比较常用的生产者<strong>优化策略。</strong></p>
</blockquote>
<h4 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h4><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生产者方 添加如下配置项即可</span></span><br><span class="line"><span class="comment"># 两个条件 满足其一即可</span></span><br><span class="line"><span class="meta">batch.size</span> = <span class="string">16384Bytes  16kb// 缓冲区大小</span></span><br><span class="line"><span class="meta">linger.ms</span> = <span class="string">毫秒值    // 缓冲区中数据的驻留时长</span></span><br></pre></td></tr></table></figure>

<h4 id="具体使用方法"><a href="#具体使用方法" class="headerlink" title="具体使用方法"></a>具体使用方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">properties.put(ProducerConfig.BATCH_SIZE_CONFIG,<span class="number">16384</span>);</span><br><span class="line">properties.put(ProducerConfig.LINGER_MS_CONFIG,<span class="number">2000</span>);</span><br></pre></td></tr></table></figure>

<h3 id="Kafka和Spring-Boot整合"><a href="#Kafka和Spring-Boot整合" class="headerlink" title="Kafka和Spring Boot整合"></a>Kafka和Spring Boot整合</h3><h4 id="创建Spring-Boot工程并选择Kakfa和SpirngBoot的整合依赖"><a href="#创建Spring-Boot工程并选择Kakfa和SpirngBoot的整合依赖" class="headerlink" title="创建Spring Boot工程并选择Kakfa和SpirngBoot的整合依赖"></a>创建Spring Boot工程并选择Kakfa和SpirngBoot的整合依赖</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">spring.kafka.bootstrap-servers</span>= <span class="string">HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.group-id</span>=<span class="string">g1</span></span><br><span class="line"><span class="meta">spring.kafka.producer.key-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="meta">spring.kafka.producer.value-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.key-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.value-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br></pre></td></tr></table></figure>

<h4 id="生产者API-1"><a href="#生产者API-1" class="headerlink" title="生产者API"></a>生产者API</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.baizhi.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.KafkaTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Scheduled;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate&lt;String,String&gt; template;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计划任务，定时发送数据</span></span><br><span class="line">    <span class="comment">// cron 秒 分 时 日 月 周 年(省略)</span></span><br><span class="line">    <span class="meta">@Scheduled</span>(cron = <span class="string">"0/10 * * * * ?"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">()</span></span>&#123;</span><br><span class="line">        template.send(<span class="string">"t5"</span>, UUID.randomUUID().toString(),<span class="string">"Hello Kafka"</span>);</span><br><span class="line">        <span class="comment">//System.out.println(new Date());</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="消费者API-1"><a href="#消费者API-1" class="headerlink" title="消费者API"></a>消费者API</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.baizhi.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.annotation.KafkaListener;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumerDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@KafkaListener</span>(topics = <span class="string">"t5"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receive</span><span class="params">(ConsumerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line">        System.out.println(record.key() + <span class="string">"\t"</span> + record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="生产者幂等操作"><a href="#生产者幂等操作" class="headerlink" title="生产者幂等操作"></a>生产者幂等操作</h3><blockquote>
<p>幂等： 指的多次操作，影响结果是一致的，这种操作方式就被成为幂等操作</p>
<p>==结论：使用Kafka生产者幂等操作原因，kafka生产者在重试发送生产数据时，多次重试操作只会在Kafka的分区队列的末尾写入一条记录==</p>
</blockquote>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571036808522.png" alt="1571036808522"></p>
<h4 id="使用方法-1"><a href="#使用方法-1" class="headerlink" title="使用方法"></a>使用方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,<span class="keyword">true</span>); <span class="comment">// 开启幂等操作支持</span></span><br><span class="line">properties.put(ProducerConfig.ACKS_CONFIG,<span class="string">"all"</span>);  <span class="comment">// ack时机 -1或者all 所有  1 leader  0 立即应答</span></span><br><span class="line">properties.put(ProducerConfig.RETRIES_CONFIG,<span class="number">5</span>);   <span class="comment">// 重复次数</span></span><br><span class="line">properties.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, <span class="number">3000</span>); <span class="comment">// 请求超时时间</span></span><br></pre></td></tr></table></figure>



<h3 id="Kafka事务"><a href="#Kafka事务" class="headerlink" title="Kafka事务"></a>Kafka事务</h3><blockquote>
<p>数据库事务： 一个连接中多个操作不可分割，是一个整体，要么同时成功，同时失败。</p>
</blockquote>
<p>Kafka的事务类似于数据库事务，每一个事务操作都需要一个唯一的事务ID（<code>Transaction-ID</code>），并且事务默认的隔离级别为<code>READ_UNCOMMITTED</code>和<code>READ_COMMITTED</code></p>
<h4 id="生产者事务"><a href="#生产者事务" class="headerlink" title="生产者事务"></a>生产者事务</h4><blockquote>
<p>生产者事务： Kakfka生产者生产的多条数据是一个整体，不可分割，要么同时写入要么同时放弃</p>
</blockquote>
<h5 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h5><ul>
<li>kafka生产者提供唯一的事务ID</li>
<li>必须开启kafka的幂等性支持</li>
</ul>
<h5 id="事务操作"><a href="#事务操作" class="headerlink" title="事务操作"></a>事务操作</h5><ul>
<li>初始化事务</li>
<li>开启事务</li>
<li>正确操作 提交事务</li>
<li>操作失败  回滚事务</li>
</ul>
<h5 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h5><h6 id="生产者API-2"><a href="#生产者API-2" class="headerlink" title="生产者API"></a>生产者API</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> transaction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kafka 生产者的测试类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 准备Kafka生产者配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        <span class="comment">// string 序列化（Object ---&gt; byte[]）器</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 事务ID， 唯一不可重复</span></span><br><span class="line">        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,UUID.randomUUID().toString());</span><br><span class="line">        <span class="comment">// 开启幂等操作支持</span></span><br><span class="line">        properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,<span class="keyword">true</span>);</span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG,<span class="string">"all"</span>);  <span class="comment">// ack时机 -1或者all 所有  1 leader  0 立即应答</span></span><br><span class="line">        properties.put(ProducerConfig.RETRIES_CONFIG,<span class="number">5</span>);   <span class="comment">// 重复次数</span></span><br><span class="line">        properties.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, <span class="number">3000</span>); <span class="comment">// 请求超时时间</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 初始化事务</span></span><br><span class="line">        producer.initTransactions();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 开启事务</span></span><br><span class="line">        producer.beginTransaction();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//3. 生产记录并将其发布</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">50</span>; i &lt; <span class="number">60</span>; i++) &#123;</span><br><span class="line">                <span class="keyword">if</span>(i == <span class="number">56</span>) &#123;</span><br><span class="line">                    <span class="keyword">int</span> m = <span class="number">1</span>/<span class="number">0</span>; <span class="comment">//人为制造错误</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// key不为null  第一种策略</span></span><br><span class="line">                ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"t3"</span>, UUID.randomUUID().toString(),<span class="string">"Hello Kafka"</span>+i);</span><br><span class="line">                <span class="comment">// key为null 轮询策略</span></span><br><span class="line">                producer.send(record);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 提交事务</span></span><br><span class="line">            producer.commitTransaction();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="comment">// 取消事务</span></span><br><span class="line">            producer.abortTransaction();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">//4. 释放资源</span></span><br><span class="line">            producer.flush();</span><br><span class="line">            producer.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h6 id="消费者API-2"><a href="#消费者API-2" class="headerlink" title="消费者API"></a>消费者API</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 其余代码 一致</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 修改消费者默认的事务隔离级别</span></span><br><span class="line">properties.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG,<span class="string">"read_committed"</span>);</span><br></pre></td></tr></table></figure>

<h4 id="消费生产并存事务（consume-transform-produce）"><a href="#消费生产并存事务（consume-transform-produce）" class="headerlink" title="消费生产并存事务（consume-transform-produce）"></a>消费生产并存事务（consume-transform-produce）</h4><blockquote>
<p>指消费和生产处于同一个事务环境中，要么消费生产同时成功，要么同时失败</p>
</blockquote>
<h5 id="要求-1"><a href="#要求-1" class="headerlink" title="要求"></a>要求</h5><ul>
<li>kafka生产者提供唯一的事务ID</li>
<li>必须开启kafka的幂等性支持</li>
<li>关闭<code>offset</code>的自动提交功能</li>
<li>不能调用手动提交的方法，如: <code>consumer.commitSync();</code></li>
</ul>
<h5 id="实战-1"><a href="#实战-1" class="headerlink" title="实战"></a>实战</h5><blockquote>
<p>创建消费Topic，以及发布的Topic</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092 --topic t6 --partitions 3 --replication-factor 3 --create</span><br><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092 --topic t7 --partitions 3 --replication-factor 3 --create</span><br><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]#</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> transaction.ctp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费生产并存事务</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumeTransformProduceDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 初始化生产者和消费者的配置对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(consumerConfig());</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(producerConfig());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 消费者订阅topic</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"t6"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 事务操作</span></span><br><span class="line">        producer.initTransactions();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            producer.beginTransaction();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">5</span>));</span><br><span class="line">                Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">                <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                    <span class="comment">// 需要业务处理的内容</span></span><br><span class="line">                    System.out.println(record.key() + <span class="string">"---&gt;"</span> + record.value());</span><br><span class="line">                    producer.send(<span class="keyword">new</span> ProducerRecord&lt;String,String&gt;(<span class="string">"t7"</span>,<span class="string">"t7:"</span>+record.value()));</span><br><span class="line">                    <span class="comment">// 模拟错误</span></span><br><span class="line">                    <span class="comment">// int m = 1/0;</span></span><br><span class="line">                    <span class="comment">// 将消费位置记录到map集合中</span></span><br><span class="line">                    offsets.put(<span class="keyword">new</span> TopicPartition(<span class="string">"t6"</span>,record.partition()),<span class="keyword">new</span> OffsetAndMetadata(record.offset()+<span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 维护消费位置  将事务内的消费位置信息 提交到kafka中</span></span><br><span class="line">                producer.sendOffsetsToTransaction(offsets,<span class="string">"g1"</span>);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 正确操作 提交事务</span></span><br><span class="line">                producer.commitTransaction();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                producer.abortTransaction();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Properties <span class="title">producerConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, UUID.randomUUID().toString());</span><br><span class="line">        properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, Boolean.TRUE);</span><br><span class="line">        properties.put(ProducerConfig.RETRIES_CONFIG, <span class="number">5</span>);</span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG, <span class="string">"all"</span>);</span><br><span class="line">        properties.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, <span class="number">3000</span>);</span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">2000</span>);</span><br><span class="line">        <span class="keyword">return</span> properties;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Properties <span class="title">consumerConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"g1"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">false</span>);</span><br><span class="line">        properties.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, <span class="string">"read_committed"</span>);</span><br><span class="line">        <span class="keyword">return</span> properties;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>作业：</p>
<ol>
<li>重构周六用户注册系统</li>
<li>课堂练习</li>
<li>上网查找总结MQ产品具体的应用场景 <a href="https://www.cnblogs.com/leeego-123/p/10900256.html" target="_blank" rel="noopener">https://www.cnblogs.com/leeego-123/p/10900256.html</a></li>
</ol>
<h1 id="Kafka-Streaming"><a href="#Kafka-Streaming" class="headerlink" title="Kafka Streaming"></a>Kafka Streaming</h1><h2 id="一、什么是批处理和流处理？"><a href="#一、什么是批处理和流处理？" class="headerlink" title="一、什么是批处理和流处理？"></a>一、什么是批处理和流处理？</h2><p>大数据进行处理时有两种处理方式： 批处理和流处理</p>
<h3 id="批处理-Batch-Processing"><a href="#批处理-Batch-Processing" class="headerlink" title="批处理 Batch Processing"></a>批处理 Batch Processing</h3><p>在批处理中，新到达的数据元素被收集到一个组中。整个组在未来的时间进行处理（作为批处理，因此称为“批处理”）。确切地说，何时处理每个组可以用多种方式来确定 - 例如，它可以基于预定的时间间隔（例如，每五分钟，处理任何新的数据已被收集）或在某些触发的条件下（例如，处理只要它包含五个数据元素或一旦它拥有超过1MB的数据）。</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/20190830063445252.gif" alt="在这里插入图片描述"></p>
<p>批处理模式中使用的数据集通常符合下列特征</p>
<ul>
<li>有界：批处理数据集代表数据的有限集合</li>
<li>持久：数据通常始终存储在某种类型的持久存储位置中</li>
<li>大量：批处理操作通常是处理极为海量数据集的唯一方法</li>
<li>高延迟：大量数据的处理需要付出大量时间，因此批处理不适合对处理时间要求较高的场合</li>
</ul>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/aHR0cHM6Ly9hc2sucWNsb3VkaW1nLmNvbS9odHRwLXNhdmUvZGV2ZWxvcGVyLW5ld3MvdjZiZjhxZ3B3dC5qcGVn.jpg" alt="img"></p>
<p><strong>批处理架构的应用场景：日志分析、计费应用程序、数据仓库等</strong>，相关的开源项目（由Google MapReduce衍生）：Apache Hadoop、Apache Spark、Apache Flink等</p>
<h3 id="流处理-Stream-Processing"><a href="#流处理-Stream-Processing" class="headerlink" title="流处理 Stream Processing"></a>流处理 Stream Processing</h3><p>在流处理中，每一条新数据都会在到达时进行处理。与批处理不同，在下一批处理间隔之前不会等待，数据将作为单独的碎片进行处理，而不是一次处理批量。尽管每个新的数据都是单独处理的，但许多流处理系统也支持“窗口”操作，这些操作允许处理也引用在当前数据到达之前和/或之后在指定时间间隔内到达的数据。</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/20190830064713109.gif" alt="在这里插入图片描述"></p>
<p>流处理模式中使用的数据集通常符合下列特征</p>
<ul>
<li>无界：流处理的输入数据基本上都是无边界数据，而流处理系统将依据具体的应用场景来关注数据的事件时间还是处理时间</li>
<li>高吞吐：大多数的流处理框架都支持分布式并行处理流数据</li>
<li>低延迟：流处理所需的响应时间应该以毫秒（或微秒）来进行计算</li>
</ul>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/aHR0cHM6Ly9hc2sucWNsb3VkaW1nLmNvbS9odHRwLXNhdmUvZGV2ZWxvcGVyLW5ld3MvcWg4dGZlYjlwNC5qcGVn.jpg" alt="在这里插入图片描述"></p>
<p><strong>流处理的应用场景：实时监控、风险评估、实时商业智能（如智能汽车）、实时分析等</strong>，开源项目：Apache Kafka、Apache Flink、Apache Storm、Apache Samza等。</p>
<h2 id="二、Kafka-Straming概述"><a href="#二、Kafka-Straming概述" class="headerlink" title="二、Kafka Straming概述"></a>二、Kafka Straming概述</h2><p>Kafka Streams是一个用于构建应用程序和微服务的<strong>客户端库</strong>，其中的<strong>输入和输出</strong>数据存储在Kafka集群中。它结合了在客户端编写和部署标准<strong>Java和Scala</strong>应用程序的简单性，以及Kafka<strong>服务器端集群技术的优点</strong>。</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ol>
<li>弹性、高可扩展、容错</li>
<li>可以部署在容器、虚拟机、单独、云环境中</li>
<li>同样适用于小型、中型和大型用例</li>
<li>集成Kafka Security</li>
<li>写标准的JAVA和Scala应用</li>
<li>精确一次处理语义（exactly once）</li>
<li>无需单独的处理群集</li>
<li>支持多种开发平台</li>
</ol>
<h3 id="核心概念-1"><a href="#核心概念-1" class="headerlink" title="核心概念"></a>核心概念</h3><ul>
<li>==Topology(拓扑)==： 一个用来进行流数据处理的任务，类似于MapReduce的Job。对于MapReduce Job一定会运行结束，而拓扑Topology任务会持续运行，除非人为手动关闭</li>
<li>==Stream(流)==:  数据流，  源源不断，持续产生的数据集合</li>
<li>==Processor（处理器）==： 代表Topology一个计算单元（逻辑）</li>
<li>==State（状态）==： 流处理计算产生的中间结果，通常用于容错和故障恢复</li>
<li>==Time（时间）==： 数据产生时间 &lt;=数据摄入时间&lt;=数据处理时间</li>
</ul>
<blockquote>
<p>注意：<strong>所谓的流处理就是通过Topology编织程序对Stream中Record元素的处理的逻辑/流程。</strong></p>
</blockquote>
<h3 id="架构篇"><a href="#架构篇" class="headerlink" title="架构篇"></a>架构篇</h3><h3 id="架构-1"><a href="#架构-1" class="headerlink" title="架构"></a>架构</h3><p>Kafka Streams通过构建Kafka生产者和消费者库并利用Kafka的本机功能来提供数据并行性，分布式协调，容错和操作简便性，从而简化了应用程序开发。</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571122121002.png" alt="1571122121002"></p>
<p>Kafka的消息分区用于存储和传递消息， Kafka Streams对数据进行分区以进行处理。 Kafka Streams使用Partition和Task的概念作为基于Kafka Topic分区的并行模型的逻辑单元。在并行化的背景下，Kafka Streams和Kafka之间有着密切的联系：</p>
<ol>
<li>每个stream分区都是完全有序的数据记录序列，并映射到Kafka Topic分区。</li>
<li>Stream中的数据记录映射到该Topic的Kafka消息。</li>
<li>数据记录的key决定了Kafka和Kafka Streams中数据的分区，即数据如何路由到Topic的特定分区。</li>
</ol>
<h4 id="任务的并行度"><a href="#任务的并行度" class="headerlink" title="任务的并行度"></a>任务的并行度</h4><p>Kafka Streams基于应用程序的输入流分区创建固定数量的Task，每个任务(Task)分配来自输入流的分区列表（即Kafka主题）。分区到任务的分配永远不会改变，因此每个任务都是应用程序的固定平行单元。然后，任务可以根据分配的分区实例化自己的处理器拓扑; 它们还为每个分配的分区维护一个缓冲区，并从这些记录缓冲区一次一个地处理消息。因此，流任务可以独立并行地处理，无需人工干预。</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571122141260.png" alt="1571122141260"></p>
<p>用户可以启动多个KafkaStream实例，这样等价启动了多个Stream Tread，每个Thread处理1~n个Task。一个Task对应一个分区，因此Kafka Stream流处理的并行度不会超越Topic的分区数。需要值得注意的是Kafka的每个Task都维护这自身的一些状态，线程之间不存在状态共享和通信。因此Kafka在实现流处理的过程中扩展是非常高效的。</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571122150248.png" alt="1571122150248"></p>
<h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><p>Kafka Streams构建于Kafka本地集成的容错功能之上。 Kafka分区具有高可用性和复制性;因此当流数据持久保存到Kafka时，即使应用程序失败并需要重新处理它也可用。 Kafka Streams中的任务利用Kafka消费者客户端提供的容错功能来处理故障。如果任务运行的计算机故障了，Kafka Streams会自动在其余一个正在运行的应用程序实例中重新启动该任务。</p>
<p>此外，Kafka Streams还确保local state store也很有力处理故障容错。对于每个state store，Kafka Stream维护一个带有副本changelog的Topic，在该Topic中跟踪任何状态更新。这些changelog Topic也是分区的，该分区和Task是一一对应的。如果Task在运行失败并Kafka Stream会在另一台计算机上重新启动该任务，Kafka Streams会保证在重新启动对新启动的任务的处理之前，通过重播相应的更改日志主题，将其关联的状态存储恢复到故障之前的内容。</p>
<h2 id="三、实战操作"><a href="#三、实战操作" class="headerlink" title="三、实战操作"></a>三、实战操作</h2><h3 id="low-level"><a href="#low-level" class="headerlink" title="low-level"></a>low-level</h3><blockquote>
<p>自定义Processor，编程较为复杂，需要手动编程Topology</p>
</blockquote>
<h4 id="maven依赖"><a href="#maven依赖" class="headerlink" title="maven依赖"></a>maven依赖</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-streams --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-streams<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> streams.lowlevel.statefuless;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.LongSerializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.Serdes;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.KafkaStreams;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.StreamsConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.Topology;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.processor.Processor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.processor.ProcessorSupplier;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过流处理 实现实时的WordCount</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountApplication</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 指定Kafka Streaming配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        <span class="comment">// 声明key和value的序列化和反序列化器</span></span><br><span class="line">        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        <span class="comment">// 流处理应用程序的名称 默认会成为消费组的名称</span></span><br><span class="line">        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string">"wordcount-application"</span>);</span><br><span class="line">        properties.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 手动编织拓扑任务</span></span><br><span class="line">        Topology topology = <span class="keyword">new</span> Topology();</span><br><span class="line"></span><br><span class="line">        topology.addSource(<span class="string">"s1"</span>, <span class="string">"t8"</span>);</span><br><span class="line">        <span class="comment">// 添加计算计算逻辑</span></span><br><span class="line">        topology.addProcessor(<span class="string">"p1"</span>, <span class="keyword">new</span> ProcessorSupplier() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Processor <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> WordCountProcessor();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">"s1"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// s1 ---&gt; p1 ---&gt; k1</span></span><br><span class="line">        <span class="comment">// 注意：此时结果输出类型不匹配默认类型，需要手动指定输出类型</span></span><br><span class="line">        topology.addSink(<span class="string">"k1"</span>, <span class="string">"t9"</span>, <span class="keyword">new</span> StringSerializer(),<span class="keyword">new</span> LongSerializer(),<span class="string">"p1"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 初始化KafkaStreaming应用</span></span><br><span class="line">        KafkaStreams kafkaStreams = <span class="keyword">new</span> KafkaStreams(topology, properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 启动流处理应用</span></span><br><span class="line">        kafkaStreams.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="创建输入和输出Topic"><a href="#创建输入和输出Topic" class="headerlink" title="创建输入和输出Topic"></a>创建输入和输出Topic</h4><blockquote>
<p><u>注意输入Topic分区数量必须为1个</u></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092 --topic t9 --partitions 1 --replication-factor 1 --create</span><br><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]# bin/kafka-topics.sh --bootstrap-server HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092 --topic t8 --partitions 1 --replication-factor 1 --create</span><br><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]#</span><br></pre></td></tr></table></figure>

<h4 id="生产者-1"><a href="#生产者-1" class="headerlink" title="生产者"></a>生产者</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@HadoopNode01 kafka_2.11-2.2.0]# bin/kafka-console-producer.sh --topic t8  --broker-list HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092</span><br><span class="line"><span class="meta">&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="消费者-1"><a href="#消费者-1" class="headerlink" title="消费者"></a>消费者</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092 \</span><br><span class="line">   --topic t9 \</span><br><span class="line">   --from-beginning \</span><br><span class="line">   --formatter kafka.tools.DefaultMessageFormatter \</span><br><span class="line">   --property print.key=true \</span><br><span class="line">   --property print.value=true \</span><br><span class="line">   --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \</span><br><span class="line">   --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer</span><br></pre></td></tr></table></figure>

<h4 id="分析原因"><a href="#分析原因" class="headerlink" title="分析原因"></a>分析原因</h4><p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571130666409.png" alt="1571130666409"></p>
<p>使用HashMap存放流处理计算的累积结果，存在如下问题：</p>
<ul>
<li>应用重启，会操作Map集合中累积的数据丢失</li>
<li>Map集合的容量是有上限的，并且不可能无限制的在集合中存放数据，这样做容易造成JVM的内存溢出，导致服务奔溃。</li>
</ul>
<h4 id="状态管理"><a href="#状态管理" class="headerlink" title="状态管理"></a>状态管理</h4><h5 id="流处理应用的代码（local-state-store）"><a href="#流处理应用的代码（local-state-store）" class="headerlink" title="流处理应用的代码（local state store）"></a>流处理应用的代码（local state store）</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> streams.lowlevel.stateful;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.LongSerializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.Serdes;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.KafkaStreams;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.StreamsConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.Topology;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.processor.Processor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.processor.ProcessorSupplier;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.state.KeyValueStore;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.state.StoreBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.state.Stores;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过流处理 实现实时的WordCount</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountApplication</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 指定Kafka Streaming配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        <span class="comment">// 声明key和value的序列化和反序列化器</span></span><br><span class="line">        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        <span class="comment">// 流处理应用程序的名称 默认会成为消费组的名称</span></span><br><span class="line">        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string">"wordcount-application"</span>);</span><br><span class="line">        properties.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 手动编织拓扑任务</span></span><br><span class="line">        Topology topology = <span class="keyword">new</span> Topology();</span><br><span class="line"></span><br><span class="line">        topology.addSource(<span class="string">"s1"</span>, <span class="string">"t8"</span>);</span><br><span class="line">        <span class="comment">// 添加计算计算逻辑</span></span><br><span class="line">        topology.addProcessor(<span class="string">"p1"</span>, <span class="keyword">new</span> ProcessorSupplier() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Processor <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> WordCountProcessor();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">"s1"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 状态管理的初始化代码</span></span><br><span class="line">        StoreBuilder&lt;KeyValueStore&lt;String, Long&gt;&gt; countStoreSupplier = Stores.keyValueStoreBuilder(</span><br><span class="line">                Stores.persistentKeyValueStore(<span class="string">"Counts"</span>), <span class="comment">// 状态存储的类型</span></span><br><span class="line">                Serdes.String(),  <span class="comment">// 状态存储的key的序列化和反序列化器</span></span><br><span class="line">                Serdes.Long())    <span class="comment">// value的序列化和反序列化器</span></span><br><span class="line">                .withLoggingDisabled(); <span class="comment">// 关闭remote state store   disable backing up the store to a changelog topic</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将p1处理器计算产生的中间结果 状态存储</span></span><br><span class="line">        topology.addStateStore(countStoreSupplier,<span class="string">"p1"</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// s1 ---&gt; p1 ---&gt; k1</span></span><br><span class="line">        <span class="comment">// 注意：此时结果输出类型不匹配默认类型，需要手动指定输出类型</span></span><br><span class="line">        topology.addSink(<span class="string">"k1"</span>, <span class="string">"t9"</span>, <span class="keyword">new</span> StringSerializer(),<span class="keyword">new</span> LongSerializer(),<span class="string">"p1"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 初始化KafkaStreaming应用</span></span><br><span class="line">        KafkaStreams kafkaStreams = <span class="keyword">new</span> KafkaStreams(topology, properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 启动流处理应用</span></span><br><span class="line">        kafkaStreams.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="自定义处理器代码"><a href="#自定义处理器代码" class="headerlink" title="自定义处理器代码"></a>自定义处理器代码</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> streams.lowlevel.stateful;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.KeyValue;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.processor.Processor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.processor.ProcessorContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.processor.PunctuationType;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.processor.Punctuator;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.state.KeyValueIterator;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.state.KeyValueStore;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountProcessor</span> <span class="keyword">implements</span> <span class="title">Processor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ProcessorContext processorContext;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> KeyValueStore&lt;String, Long&gt; state;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化方法</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> processorContext 处理器的上下文对象</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(ProcessorContext processorContext)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = (KeyValueStore&lt;String, Long&gt;) processorContext.getStateStore(<span class="string">"Counts"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.processorContext = processorContext;</span><br><span class="line">        <span class="comment">// 周期性将处理器的处理结果 发送给下游的处理器</span></span><br><span class="line">        processorContext.schedule(Duration.ofSeconds(<span class="number">1</span>), PunctuationType.STREAM_TIME, <span class="keyword">new</span> Punctuator() &#123;</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * 指定方法</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@param</span> timestamp</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">punctuate</span><span class="params">(<span class="keyword">long</span> timestamp)</span> </span>&#123;</span><br><span class="line">                KeyValueIterator&lt;String, Long&gt; iterator = state.all();</span><br><span class="line">                <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">                    KeyValue&lt;String, Long&gt; keyValue = iterator.next();</span><br><span class="line">                    processorContext.forward(keyValue.key, keyValue.value);</span><br><span class="line">                &#125;</span><br><span class="line">                iterator.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;); <span class="comment">// 第三个参数：周期性执行的内容</span></span><br><span class="line">        processorContext.commit();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理方法</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(String key, String value)</span> </span>&#123;</span><br><span class="line">        String[] words = value.split(<span class="string">" "</span>);</span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">            Long num = state.get(word);</span><br><span class="line">            System.out.println(word + <span class="string">"\t"</span> + num);</span><br><span class="line">            <span class="keyword">if</span> (num == <span class="keyword">null</span>) &#123;</span><br><span class="line">                state.put(word, <span class="number">1L</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                state.put(word, num + <span class="number">1L</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关闭</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>问题：</strong></p>
<p><code>Exception in thread &quot;wordcount-application-834c5456-d4fa-4077-bcb9-14ad824e0196-StreamThread-2&quot; java.lang.UnsatisfiedLinkError: C:\Users\Administrator\AppData\Local\Temp\librocksdbjni6558818401015537035.dll: Can&#39;t find dependent libraries</code></p>
<p><strong>解决办法：</strong></p>
<p>​        从<a href="https://link.jianshu.com/?t=https://www.microsoft.com/en-us/download/details.aspx?id=48145" target="_blank" rel="noopener">https://www.microsoft.com/en-us/download/details.aspx?id=48145</a>下载<em>Microsoft Visual C++ 2015 Redistributable 并安装。</em></p>
<p>​         如果还未解决，请安装所有的VC++ 版本</p>
</blockquote>
<h5 id="Remote-State-Store"><a href="#Remote-State-Store" class="headerlink" title="Remote State Store"></a>Remote State Store</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String,String&gt; config = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// kafka topic的数据删除策略： delete(默认) 数据保留周期 7天</span></span><br><span class="line"><span class="comment">//                          compact(紧凑)  新值覆盖旧值</span></span><br><span class="line"><span class="comment">// Hello 2</span></span><br><span class="line"><span class="comment">// Hello 6</span></span><br><span class="line">config.put(<span class="string">"cleanup.policy"</span>,<span class="string">"compact"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 状态管理的初始化代码</span></span><br><span class="line">StoreBuilder&lt;KeyValueStore&lt;String, Long&gt;&gt; countStoreSupplier = Stores.keyValueStoreBuilder(</span><br><span class="line">    Stores.persistentKeyValueStore(<span class="string">"Counts"</span>), <span class="comment">// 状态存储的类型</span></span><br><span class="line">    Serdes.String(),  <span class="comment">// 状态存储的key的序列化和反序列化器</span></span><br><span class="line">    Serdes.Long())    <span class="comment">// value的序列化和反序列化器</span></span><br><span class="line">    .withLoggingEnabled(config); <span class="comment">// 开启remote state store</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>compact数据删除策略表示：数据写入Topic时，如果key存在则新值覆盖原有的历史值，key不存在则追加数据</p>
</blockquote>
<h3 id="high-level"><a href="#high-level" class="headerlink" title="high-level"></a>high-level</h3><blockquote>
<p>通过Kafka Streaming提供的DSL编程风格，编写流处理应用（各种操作算子会自动编织为Topology）</p>
</blockquote>
<p>Kafka Streams DSL（Domain Specific Language）构建于Streams Processor API之上。它是大多数用户推荐的，特别是初学者。大多数数据处理操作只能用几行DSL代码表示。在 Kafka Streams DSL 中有这么几个概念<code>KTable</code>、<code>KStream</code>和<code>GlobalKTable</code></p>
<p>KStream是一个数据流，可以认为所有记录都通过Insert only的方式插入进这个数据流里。而KTable代表一个完整的数据集，可以理解为数据库中的表。由于每条记录都是Key-Value对，这里可以将Key理解为数据库中的Primary Key，而Value可以理解为一行记录。可以认为KTable中的数据都是通过Update only的方式进入的。也就意味着，如果KTable对应的Topic中新进入的数据的Key已经存在，那么从KTable只会取出同一Key对应的最后一条数据，相当于新的数据更新了旧的数据。</p>
<p>以下图为例，假设有一个KStream和KTable，基于同一个Topic创建，并且该Topic中包含如下图所示5条数据。此时遍历KStream将得到与Topic内数据完全一样的所有5条数据，且顺序不变。而此时遍历KTable时，因为这5条记录中有3个不同的Key，所以将得到3条记录，每个Key对应最新的值，并且这三条数据之间的顺序与原来在Topic中的顺序保持一致。这一点与Kafka的日志compact相同。</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/963903-20180823012822162-142241598.png" alt="img"></p>
<p>此时如果对该KStream和KTable分别基于key做Group，对Value进行Sum，得到的结果将会不同。对KStream的计算结果是&lt;Jack，4&gt;，&lt;Lily，7&gt;，&lt;Mike，4&gt;。而对Ktable的计算结果是&lt;Mike，4&gt;，&lt;Jack，3&gt;，&lt;Lily，5&gt;。</p>
<blockquote>
<p><strong>GlobalKTable</strong>:和KTable类似，不同点在于KTable只能表示一个分区的信息，但是GlobalKTable表示的是全局的状态信息。</p>
</blockquote>
<h4 id="Maven依赖-1"><a href="#Maven依赖-1" class="headerlink" title="Maven依赖"></a>Maven依赖</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-streams<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="应用-1"><a href="#应用-1" class="headerlink" title="应用"></a>应用</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> streams.highlevel.statefulless;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.Serdes;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.kstream.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kafka streaming dsl风格（高级API）版的WordCount</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 指定流处理应用的配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"HadoopNode01:9092,HadoopNode02:9092,HadoopNode03:9092"</span>);</span><br><span class="line">        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string">"wordcount-highlevel-application"</span>);</span><br><span class="line">        properties.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 编织拓扑任务</span></span><br><span class="line">        StreamsBuilder sb = <span class="keyword">new</span> StreamsBuilder();</span><br><span class="line">        KStream&lt;String, String&gt; stream = sb.stream(<span class="string">"t10"</span>);</span><br><span class="line">        KTable&lt;String, Long&gt; kTable = stream</span><br><span class="line">                <span class="comment">// null hello</span></span><br><span class="line">                <span class="comment">// null world</span></span><br><span class="line">                .flatMap((key, value) -&gt; &#123;</span><br><span class="line">                    String[] words = value.toLowerCase().split(<span class="string">" "</span>);</span><br><span class="line">                    ArrayList&lt;KeyValue&lt;String, String&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                    <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                        KeyValue&lt;String, String&gt; keyValue = <span class="keyword">new</span> KeyValue&lt;&gt;(key, word);</span><br><span class="line">                        list.add(keyValue);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">return</span> list;</span><br><span class="line"></span><br><span class="line">                &#125;)</span><br><span class="line">                <span class="comment">// hello 1L</span></span><br><span class="line">                <span class="comment">// world 1L</span></span><br><span class="line">                .map((k, v) -&gt; <span class="keyword">new</span> KeyValue&lt;String, Long&gt;(v, <span class="number">1L</span>))</span><br><span class="line">                <span class="comment">// hello [1,1...]</span></span><br><span class="line">                <span class="comment">// shuffle</span></span><br><span class="line">                .groupByKey(Grouped.with(Serdes.String(), Serdes.Long()))</span><br><span class="line">                <span class="comment">// hello 2</span></span><br><span class="line">                .count();</span><br><span class="line"></span><br><span class="line">        kTable.toStream().to(<span class="string">"t11"</span>, Produced.with(Serdes.String(), Serdes.Long()));</span><br><span class="line"></span><br><span class="line">        Topology topology = sb.build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 打印自动生产的Topology信息</span></span><br><span class="line">        System.out.println(topology.describe().toString());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 初始化流处理应用</span></span><br><span class="line">        KafkaStreams kafkaStreams = <span class="keyword">new</span> KafkaStreams(topology, properties);</span><br><span class="line">        <span class="comment">//4. 启动流处理应用</span></span><br><span class="line">        kafkaStreams.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="分析拓扑运行过程"><a href="#分析拓扑运行过程" class="headerlink" title="分析拓扑运行过程"></a>分析拓扑运行过程</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Topologies:</span><br><span class="line">   Sub-topology: 0</span><br><span class="line">    Source: KSTREAM-SOURCE-0000000000 (topics: [t10])</span><br><span class="line">      --&gt; KSTREAM-FLATMAP-0000000001</span><br><span class="line">    Processor: KSTREAM-FLATMAP-0000000001 (stores: [])</span><br><span class="line">      --&gt; KSTREAM-MAP-0000000002</span><br><span class="line">      &lt;-- KSTREAM-SOURCE-0000000000</span><br><span class="line">    Processor: KSTREAM-MAP-0000000002 (stores: [])</span><br><span class="line">      --&gt; KSTREAM-FILTER-0000000006</span><br><span class="line">      &lt;-- KSTREAM-FLATMAP-0000000001</span><br><span class="line">    Processor: KSTREAM-FILTER-0000000006 (stores: [])</span><br><span class="line">      --&gt; KSTREAM-SINK-0000000005</span><br><span class="line">      &lt;-- KSTREAM-MAP-0000000002</span><br><span class="line">    Sink: KSTREAM-SINK-0000000005 (topic: KSTREAM-AGGREGATE-STATE-STORE-0000000003-repartition)</span><br><span class="line">      &lt;-- KSTREAM-FILTER-0000000006</span><br><span class="line"></span><br><span class="line">  Sub-topology: 1</span><br><span class="line">    Source: KSTREAM-SOURCE-0000000007 (topics: [KSTREAM-AGGREGATE-STATE-STORE-0000000003-repartition])</span><br><span class="line">      --&gt; KSTREAM-AGGREGATE-0000000004</span><br><span class="line">    Processor: KSTREAM-AGGREGATE-0000000004 (stores: [KSTREAM-AGGREGATE-STATE-STORE-0000000003])</span><br><span class="line">      --&gt; KTABLE-TOSTREAM-0000000008</span><br><span class="line">      &lt;-- KSTREAM-SOURCE-0000000007</span><br><span class="line">    Processor: KTABLE-TOSTREAM-0000000008 (stores: [])</span><br><span class="line">      --&gt; KSTREAM-SINK-0000000009</span><br><span class="line">      &lt;-- KSTREAM-AGGREGATE-0000000004</span><br><span class="line">    Sink: KSTREAM-SINK-0000000009 (topic: t11)</span><br><span class="line">      &lt;-- KTABLE-TOSTREAM-0000000008</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/1571211039841.png" alt="1571211039841"></p>
<blockquote>
<p>剖析：</p>
<ol>
<li>在kafka streaming拓扑关系图中有两个子拓扑Sub-topology: 0和Sub-topology: 1</li>
<li>Sub-topology: 0的<code>KSTREAM-SOURCE-0000000000会</code>将topic 10中的record作为数据源，然后经过处理器（Processor）<code>KSTREAM-FLATMAP-0000000001</code>、<code>KSTREAM-MAP-0000000002</code>、<code>KSTREAM-FILTER-0000000006</code>（<em>过滤掉key为空的中间结果</em>）,最终将处理完成的结果存放到topic <code>KSTREAM-AGGREGATE-STATE-STORE-0000000003-repartition</code>中。</li>
</ol>
<p><strong>为什么这里需要*-repartition的topic呢？主要原因是保证在shuffle结束后key相同的record存放在*-repartition相同的分区中，这样就为下一步的统计做好了准备</strong></p>
<ol start="3">
<li>Sub-topology: 1的<code>KSTREAM-SOURCE-0000000007</code>将<code>*-repartition</code>topic中的record作为数据源，然后经过Processor<code>KSTREAM-AGGREGATE-0000000004</code>进行聚合操作，并且将聚合的状态信息存放大topic<code>KSTREAM-AGGREGATE-STATE-STORE-0000000003</code>中，继续经过Processor<code>KTABLE-TOSTREAM-0000000008</code>，最终将处理完成的结果存放到<code>topic 11</code>中</li>
</ol>
</blockquote>
<h4 id="操作算子"><a href="#操作算子" class="headerlink" title="操作算子"></a>操作算子</h4><h5 id="无状态的操作算子-stateless"><a href="#无状态的操作算子-stateless" class="headerlink" title="无状态的操作算子(stateless)"></a>无状态的操作算子(stateless)</h5><blockquote>
<p>无状态的操作算子, 指进行数据转换操作时不会涉及到状态的管理</p>
</blockquote>
<ul>
<li><p><strong>Branch</strong></p>
<blockquote>
<p>KStream  —-&gt; KStream[]</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">KStream&lt;String, String&gt;[] kStreams = stream.branch(</span><br><span class="line">                (k, v) -&gt; v.startsWith(<span class="string">"A"</span>),   <span class="comment">// stream: A开头</span></span><br><span class="line">                (k, v) -&gt; <span class="keyword">true</span>                 <span class="comment">// 其它数据</span></span><br><span class="line">        );</span><br><span class="line">kStreams[<span class="number">0</span>].foreach((k,v) -&gt; System.out.println(k + <span class="string">"\t"</span>+v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Filter</strong></p>
<blockquote>
<p>KStream —&gt; KStream </p>
<p>保留符合Boolean条件（true）的数据</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">     .filter((k,v) -&gt; v.startsWith(<span class="string">"H"</span>))</span><br><span class="line">    .foreach((k,v) -&gt; System.out.println(k+<span class="string">"\t"</span>+v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>filterNot</strong></p>
<blockquote>
<p>KStream → KStream</p>
<p>KTable → KTable</p>
<p>保留不符合Boolean条件的数据</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">    .filterNot((k,v) -&gt; v.startsWith(<span class="string">"H"</span>))</span><br><span class="line">    .foreach((k,v) -&gt; System.out.println(k+<span class="string">"\t"</span>+v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>FlatMap</strong></p>
<blockquote>
<p>KStream → KStream</p>
<p>将一个Record展开为0-n个Record</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">     .flatMap((k,v) -&gt; Arrays.asList(</span><br><span class="line">          <span class="keyword">new</span> KeyValue&lt;String,String&gt;(k,v.toUpperCase()+<span class="string">"!"</span>),</span><br><span class="line">          <span class="keyword">new</span> KeyValue&lt;String,String&gt;(k,v.toLowerCase()+<span class="string">"?"</span>)))</span><br><span class="line">    .foreach((k,v) -&gt; System.out.println(k +<span class="string">"\t"</span> + v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>flatMapValues</strong></p>
<blockquote>
<p>KStream → KStream</p>
<p>将一个Record的value展开为1到N个新的value（key不变）</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">                <span class="comment">// null Hello World</span></span><br><span class="line">                <span class="comment">//--------------------</span></span><br><span class="line">                <span class="comment">// null Hello</span></span><br><span class="line">                <span class="comment">// null World</span></span><br><span class="line">    .flatMapValues((v) -&gt; Arrays.asList(v.split(<span class="string">" "</span>)))</span><br><span class="line">    .foreach((k, v) -&gt; System.out.println(k + <span class="string">"\t"</span> + v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Foreach</strong></p>
<blockquote>
<p>KStream → void （终止操作）</p>
<p>对KStream中的数据进行迭代遍历，无返回值</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">                <span class="comment">// null Hello World</span></span><br><span class="line">                <span class="comment">//--------------------</span></span><br><span class="line">                <span class="comment">// null Hello</span></span><br><span class="line">                <span class="comment">// null World</span></span><br><span class="line">    .flatMapValues((v) -&gt; Arrays.asList(v.split(<span class="string">" "</span>)))</span><br><span class="line">    .foreach((k, v) -&gt; System.out.println(k + <span class="string">"\t"</span> + v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>GroupBy</strong></p>
<blockquote>
<p>KStream → KGroupedStream</p>
<p>根据指定的信息 进行分区操作，注意分组时会进行Shuffle（洗牌）</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//============================groupBy===================================</span></span><br><span class="line">stream</span><br><span class="line">                <span class="comment">// null Hello World</span></span><br><span class="line">                <span class="comment">//--------------------</span></span><br><span class="line">                <span class="comment">// null Hello</span></span><br><span class="line">                <span class="comment">// null World</span></span><br><span class="line">     .flatMapValues((v) -&gt; Arrays.asList(v.split(<span class="string">" "</span>)))</span><br><span class="line">    .groupBy((k,v) -&gt; v)</span><br><span class="line">    .count()</span><br><span class="line">    .toStream()</span><br><span class="line">    .foreach((k,v) -&gt; System.out.println(k+<span class="string">"\t"</span>+v));</span><br><span class="line"><span class="comment">//======================================================================</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>GroupByKey</strong></p>
<blockquote>
<p>KStream → KGroupedStream</p>
<p>根据已存在的key值进行分区操作（洗牌）</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">                <span class="comment">// null Hello World</span></span><br><span class="line">                <span class="comment">//--------------------</span></span><br><span class="line">                <span class="comment">// null Hello</span></span><br><span class="line">                <span class="comment">// null World</span></span><br><span class="line">    .flatMapValues((v) -&gt; Arrays.asList(v.split(<span class="string">" "</span>)))</span><br><span class="line">    .map((k,v) -&gt; <span class="keyword">new</span> KeyValue&lt;String,Long&gt;(v,<span class="number">1L</span>))</span><br><span class="line">    .groupByKey(Grouped.with(Serdes.String(),Serdes.Long()))</span><br><span class="line">    .count()</span><br><span class="line">    .toStream()</span><br><span class="line">    .foreach((k,v) -&gt; System.out.println(k+<span class="string">"\t"</span>+v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Map</strong></p>
<blockquote>
<p>KStream → KStream</p>
<p>将一个流中的一条数据映射为另外一条数据</p>
</blockquote>
</li>
<li><p><strong>mapValues</strong></p>
<blockquote>
<p>类似于map操作，不同key不可变，V可变</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">    <span class="comment">// null Hello World</span></span><br><span class="line">    <span class="comment">//--------------------</span></span><br><span class="line">    <span class="comment">// null Hello</span></span><br><span class="line">    <span class="comment">// null World</span></span><br><span class="line">    .flatMapValues((v) -&gt; Arrays.asList(v.split(<span class="string">" "</span>)))</span><br><span class="line">    .map((k,v) -&gt; <span class="keyword">new</span> KeyValue&lt;&gt;(v,<span class="number">1L</span>))</span><br><span class="line">    .mapValues(v -&gt; v = v+<span class="number">1</span>)</span><br><span class="line">    .foreach((k,v) -&gt; System.out.println(k+<span class="string">"\t"</span>+v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Merge</strong></p>
<blockquote>
<p>KStream → KStream</p>
<p>将两个流合并为一个大流</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">KStream&lt;String, String&gt;[] streams = stream</span><br><span class="line">                .branch(</span><br><span class="line">                        (k, v) -&gt; v.startsWith(<span class="string">"A"</span>),</span><br><span class="line">                        (k, v) -&gt; v.startsWith(<span class="string">"B"</span>),</span><br><span class="line">                        (k, v) -&gt; <span class="keyword">true</span></span><br><span class="line">                );</span><br><span class="line">        streams[<span class="number">0</span>].merge(streams[<span class="number">2</span>])</span><br><span class="line">                .foreach((k,v) -&gt; System.out.println(k+<span class="string">"\t"</span>+v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Peek</strong></p>
<blockquote>
<p>KStream → KStream</p>
<p>探针（调试程序）： 不会改变数据流内容</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.peek((k,v) -&gt; System.out.println(k+<span class="string">"\t"</span>+v));</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Print</strong></p>
<blockquote>
<p>等价于<code>foreach((key, value) -&gt; System.out.println(key + &quot;, &quot; + value))</code></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.print(Printed.toSysOut());</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>SelectKey</strong></p>
<blockquote>
<p>KStream → KStream</p>
<p>给流中的数据，分配新的k值（k变，v不变）</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.selectKey((k,v) -&gt; <span class="string">"Hello:"</span>).print(Printed.toSysOut());</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Table to Stream</strong></p>
<blockquote>
<p>KTable → KStream</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">table.toStream();</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h5 id="有状态的操作算子-stateful"><a href="#有状态的操作算子-stateful" class="headerlink" title="有状态的操作算子(stateful)"></a>有状态的操作算子(stateful)</h5><p>有状态转换值得是每一次的处理都需要操作关联StateStore实现有状态更新。例如，在aggregating 操作中，window state store用于收集每个window的最新聚合结果。在join操作中，窗口状态存储用于收集到目前为止在定义的window边界内接收的所有记录。状态存储是容错的。如果发生故障，Kafka Streams保证在恢复处理之前完全恢复所有状态存储。</p>
<p>DSL中可用的有状态转换包括:</p>
<ul>
<li><a href="http://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-aggregating" target="_blank" rel="noopener">Aggregating</a></li>
<li><a href="http://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-joins" target="_blank" rel="noopener">Joining</a></li>
<li><a href="http://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-windowing" target="_blank" rel="noopener">Windowing</a> (as part of aggregations and joins)</li>
<li><a href="http://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-process" target="_blank" rel="noopener">Applying custom processors and transformers</a>, which may be stateful, for Processor API integration</li>
</ul>
<p>下图显示了它们之间的关系：</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-stateful_operations.png" alt="img"></p>
<ul>
<li><p>aggregate（聚合）</p>
<blockquote>
<p>KGroupedStream –&gt; KTable</p>
<p>滚动聚合： 根据分组的key，聚合values</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">                <span class="comment">// null Hello Hello</span></span><br><span class="line">     .flatMapValues(v -&gt; Arrays.asList(v.split(<span class="string">" "</span>)))</span><br><span class="line">    <span class="comment">// null Hello</span></span><br><span class="line">    <span class="comment">// null Hello</span></span><br><span class="line">    .groupBy((k,v) -&gt; v,Grouped.with(Serdes.String(),Serdes.String()))</span><br><span class="line">    <span class="comment">// Hello [Hello,Hello].length</span></span><br><span class="line">    <span class="comment">// Hello 2+0</span></span><br><span class="line">    <span class="comment">// 参数一： 初始化器  参数二：聚合器(k: word, v: [])</span></span><br><span class="line">    .aggregate(()-&gt;<span class="number">0L</span>,(k,v,aggs) -&gt; aggs + <span class="number">1L</span>,Materialized.with(Serdes.String(),Serdes.Long()))</span><br><span class="line">    .toStream()</span><br><span class="line">    .print(Printed.toSysOut());</span><br></pre></td></tr></table></figure>
</li>
<li><p>count（计数）</p>
<blockquote>
<p>KGroupedStream → KTable</p>
<p>滚动聚合： 根据分组的key，统计value的数量</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">                <span class="comment">// null Hello Hello</span></span><br><span class="line">     .flatMapValues(v -&gt; Arrays.asList(v.split(<span class="string">" "</span>)))</span><br><span class="line">    <span class="comment">// null Hello</span></span><br><span class="line">    <span class="comment">// null Hello</span></span><br><span class="line">    .groupBy((k,v) -&gt; v,Grouped.with(Serdes.String(),Serdes.String()))</span><br><span class="line">    .count()</span><br><span class="line">    .toStream()</span><br><span class="line">    .print(Printed.toSysOut());</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Reduce</strong></p>
<blockquote>
<p>KGroupedStream → KTable</p>
<p>滚动聚合：根据分组的key，合并value值列表</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">                <span class="comment">// null Hello Hello</span></span><br><span class="line">    .flatMapValues(v -&gt; Arrays.asList(v.split(<span class="string">" "</span>)))</span><br><span class="line">    <span class="comment">// null Hello</span></span><br><span class="line">    <span class="comment">// null Hello</span></span><br><span class="line">    .map((k,v) -&gt; <span class="keyword">new</span> KeyValue&lt;String,Long&gt;(v,<span class="number">1L</span>))</span><br><span class="line">    .groupByKey(Grouped.with(Serdes.String(),Serdes.Long()))</span><br><span class="line">    <span class="comment">// Hello [1,1,1]</span></span><br><span class="line">    <span class="comment">// World [1,1,1,1]</span></span><br><span class="line">    <span class="comment">// 参数一： 初始化器  参数二：聚合器(k: word, v: [])</span></span><br><span class="line">    .reduce((v1,v2) -&gt; &#123;</span><br><span class="line">        System.out.println(v1 +<span class="string">"\t"</span>+v2);</span><br><span class="line">        Long result = v1+v2;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;,Materialized.with(Serdes.String(),Serdes.Long()))</span><br><span class="line">    .toStream()</span><br><span class="line">    .print(Printed.toSysOut());</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h4 id="Window"><a href="#Window" class="headerlink" title="Window"></a>Window</h4><ul>
<li><p>Tumbling（翻滚） 固定大小 无重叠</p>
<p>翻滚窗口将流元素按照固定的时间间隔，拆分成指定的窗口，窗口和窗口间元素之间没有重叠。在下图不同颜色的record表示不同的key。可以看是在时间窗口内，每个key对应一个窗口。<code>前闭后开</code></p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-time-windows-tumbling-1571297999267.png" alt></p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/963903-20180823013225516-1830552448-1571297996894.gif" alt></p>
</li>
</ul>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.Serdes;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.utils.Bytes;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.KafkaStreams;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.KeyValue;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.StreamsBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.StreamsConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.kstream.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.state.KeyValueStore;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.state.WindowStore;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaStreamingWordCountWithWindow</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string">"wordcount22"</span>);</span><br><span class="line">        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"gaozhy:9092"</span>);</span><br><span class="line">        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line"></span><br><span class="line">        StreamsBuilder builder = <span class="keyword">new</span> StreamsBuilder();</span><br><span class="line">        <span class="comment">// 流处理 数据的来源</span></span><br><span class="line">        KStream&lt;String, String&gt; kStream = builder.stream(<span class="string">"input"</span>);</span><br><span class="line"></span><br><span class="line">        kStream</span><br><span class="line">                .flatMap((k, v) -&gt; &#123;</span><br><span class="line">                    ArrayList&lt;KeyValue&lt;String, String&gt;&gt; keyValues = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                    String[] words = v.split(<span class="string">" "</span>);</span><br><span class="line">                    <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                        keyValues.add(<span class="keyword">new</span> KeyValue&lt;String, String&gt;(k, word));</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">return</span> keyValues;</span><br><span class="line">                &#125;)</span><br><span class="line">                .map((k, v) -&gt; <span class="keyword">new</span> KeyValue&lt;String, Long&gt;(v, <span class="number">1L</span>))</span><br><span class="line">                .groupBy((k, v) -&gt; k, Grouped.with(Serdes.String(), Serdes.Long()))</span><br><span class="line">          			<span class="comment">// 滚动窗口的大小</span></span><br><span class="line">                .windowedBy(TimeWindows.of(Duration.ofSeconds(<span class="number">10</span>)))</span><br><span class="line">                .reduce((value1, value2) -&gt; value1 + value2, Materialized.&lt;String, Long, WindowStore&lt;Bytes, <span class="keyword">byte</span>[]&gt;&gt;as(<span class="string">"counts"</span>).withKeySerde(Serdes.String()).withValueSerde(Serdes.Long()))</span><br><span class="line">                .toStream()</span><br><span class="line">                .peek(((Windowed&lt;String&gt; key, Long value) -&gt; &#123;</span><br><span class="line">                    Window window = key.window();</span><br><span class="line">                    SimpleDateFormat sdf = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"HH:mm:ss"</span>);</span><br><span class="line">                    <span class="keyword">long</span> start = window.start();</span><br><span class="line">                    <span class="keyword">long</span> end = window.end();</span><br><span class="line">                    System.out.println(sdf.format(start) + <span class="string">" ~ "</span> + sdf.format(end) + <span class="string">"\t"</span> + key.key() + <span class="string">"\t"</span> + value);</span><br><span class="line">                &#125;));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 构建kafka streaming 应用</span></span><br><span class="line">        KafkaStreams kafkaStreams = <span class="keyword">new</span> KafkaStreams(builder.build(), properties);</span><br><span class="line">        kafkaStreams.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ul>
<li><p>Hopping （跳跃） 固定大小 有重叠</p>
<p>Hopping time windows是基于时间间隔的窗口。他们模拟固定大小的（可能）重叠窗口。跳跃窗口由两个属性定义：窗口大小和其提前间隔（又名“hop”）。</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-time-windows-hopping-1571297998866.png" alt></p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/963903-20180823013127357-1860834711-1571297996613.gif" alt></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.kstream.TimeWindows;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A hopping time window with a size of 5 minutes and an advance interval of 1 minute.</span></span><br><span class="line"><span class="comment">// The window's name -- the string parameter -- is used to e.g. name the backing state store.</span></span><br><span class="line">Duration windowSizeMs = Duration.ofMinutes(<span class="number">5</span>);</span><br><span class="line">Duration advanceMs =    Duration.ofMinutes(<span class="number">1</span>);</span><br><span class="line">TimeWindows.of(windowSizeMs).advanceBy(advanceMs);</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>Sliding (滑动)  固定大小 有重合  每一个窗口至少有一个事件</p>
<p>窗口只用于2个KStream进行Join计算时。该窗口的大小定义了Join两侧KStream的数据记录被认为在同一个窗口的最大时间差。假设该窗口的大小为5秒，则参与Join的2个KStream中，记录时间差小于5的记录被认为在同一个窗口中，可以进行Join计算。</p>
</li>
</ul>
<ul>
<li><p>Session   动态 无重叠 数据驱动的窗口</p>
<p>Session Window该窗口用于对Key做Group后的聚合操作中。它需要对Key做分组，然后对组内的数据根据业务需求定义一个窗口的起始点和结束点。一个典型的案例是，希望通过Session Window计算某个用户访问网站的时间。对于一个特定的用户（用Key表示）而言，当发生登录操作时，该用户（Key）的窗口即开始，当发生退出操作或者超时时，该用户（Key）的窗口即结束。窗口结束时，可计算该用户的访问时间或者点击次数等。</p>
<p>Session Windows用于将基于key的事件聚合到所谓的会话中，其过程称为session化。会话表示由定义的不活动间隔（或“空闲”）分隔的活动时段。处理的任何事件都处于任何现有会话的不活动间隙内，并合并到现有会话中。如果事件超出会话间隙，则将创建新会话。会话窗口的主要应用领域是用户行为分析。基于会话的分析可以包括简单的指标.</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-session-windows-01-1571297997083.png" alt></p>
<p>如果我们接收到另外三条记录（包括两条迟到的记录），那么绿色记录key的两个现有会话将合并为一个会话，从时间0开始到结束时间6，包括共有三条记录。蓝色记录key的现有会话将延长到时间5结束，共包含两个记录。最后，将在11时开始和结束蓝键的新会话。</p>
<p><img src="/2020/02/26/Kafka-md/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%AC%94%E8%AE%B0/Day14-kafka%E8%B5%84%E6%96%99/assets/streams-session-windows-02-1571297997111.png" alt></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.streams.kstream.SessionWindows;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A session window with an inactivity gap of 5 minutes.</span></span><br><span class="line">SessionWindows.with(Duration.ofMinutes(<span class="number">5</span>));</span><br></pre></td></tr></table></figure>

</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/22/postgreSQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="prev" title="postgreSQL学习笔记">
      <i class="fa fa-chevron-left"></i> postgreSQL学习笔记
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Apache-Kafka"><span class="nav-number">1.</span> <span class="nav-text">Apache Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、概述"><span class="nav-number">1.1.</span> <span class="nav-text">一、概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#架构"><span class="nav-number">1.1.1.</span> <span class="nav-text">架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#应用场景"><span class="nav-number">1.1.2.</span> <span class="nav-text">应用场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核心概念"><span class="nav-number">1.1.3.</span> <span class="nav-text">核心概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Topic和Log"><span class="nav-number">1.1.4.</span> <span class="nav-text">Topic和Log</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、环境搭建"><span class="nav-number">1.2.</span> <span class="nav-text">二、环境搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#准备工作"><span class="nav-number">1.2.1.</span> <span class="nav-text">准备工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装配置"><span class="nav-number">1.2.2.</span> <span class="nav-text">安装配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#环境配置"><span class="nav-number">1.2.3.</span> <span class="nav-text">环境配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动服务"><span class="nav-number">1.2.4.</span> <span class="nav-text">启动服务</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、基础使用"><span class="nav-number">1.3.</span> <span class="nav-text">三、基础使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#命令行操作"><span class="nav-number">1.3.1.</span> <span class="nav-text">命令行操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Topic使用"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">Topic使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#发布和订阅"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">发布和订阅</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#JAVA-Driver"><span class="nav-number">1.3.2.</span> <span class="nav-text">JAVA Driver</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Maven依赖"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">Maven依赖</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#准备工作-1"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">准备工作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#生产者"><span class="nav-number">1.3.2.3.</span> <span class="nav-text">生产者</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者"><span class="nav-number">1.3.2.4.</span> <span class="nav-text">消费者</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四、高级部分"><span class="nav-number">1.4.</span> <span class="nav-text">四、高级部分</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#偏移量控制"><span class="nav-number">1.4.1.</span> <span class="nav-text">偏移量控制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消费方式"><span class="nav-number">1.4.2.</span> <span class="nav-text">消费方式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#订阅（Subscribe）"><span class="nav-number">1.4.2.1.</span> <span class="nav-text">订阅（Subscribe）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#指定消费分区"><span class="nav-number">1.4.2.2.</span> <span class="nav-text">指定消费分区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#重置消费位置"><span class="nav-number">1.4.2.3.</span> <span class="nav-text">重置消费位置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消费组"><span class="nav-number">1.4.3.</span> <span class="nav-text">消费组</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自定义对象类型的传输"><span class="nav-number">1.4.4.</span> <span class="nav-text">自定义对象类型的传输</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#序列化接口"><span class="nav-number">1.4.4.1.</span> <span class="nav-text">序列化接口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义对象"><span class="nav-number">1.4.4.2.</span> <span class="nav-text">自定义对象</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#导入工具包的依赖jar包"><span class="nav-number">1.4.4.3.</span> <span class="nav-text">导入工具包的依赖jar包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义编解码器类"><span class="nav-number">1.4.4.4.</span> <span class="nav-text">自定义编解码器类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#测试"><span class="nav-number">1.4.4.5.</span> <span class="nav-text">测试</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#生产者API"><span class="nav-number">1.4.4.5.1.</span> <span class="nav-text">生产者API</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#消费者API"><span class="nav-number">1.4.4.5.2.</span> <span class="nav-text">消费者API</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#生产者的批量发送"><span class="nav-number">1.4.5.</span> <span class="nav-text">生产者的批量发送</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用方法"><span class="nav-number">1.4.5.1.</span> <span class="nav-text">使用方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#具体使用方法"><span class="nav-number">1.4.5.2.</span> <span class="nav-text">具体使用方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka和Spring-Boot整合"><span class="nav-number">1.4.6.</span> <span class="nav-text">Kafka和Spring Boot整合</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建Spring-Boot工程并选择Kakfa和SpirngBoot的整合依赖"><span class="nav-number">1.4.6.1.</span> <span class="nav-text">创建Spring Boot工程并选择Kakfa和SpirngBoot的整合依赖</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#修改配置文件"><span class="nav-number">1.4.6.2.</span> <span class="nav-text">修改配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#生产者API-1"><span class="nav-number">1.4.6.3.</span> <span class="nav-text">生产者API</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者API-1"><span class="nav-number">1.4.6.4.</span> <span class="nav-text">消费者API</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#生产者幂等操作"><span class="nav-number">1.4.7.</span> <span class="nav-text">生产者幂等操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用方法-1"><span class="nav-number">1.4.7.1.</span> <span class="nav-text">使用方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka事务"><span class="nav-number">1.4.8.</span> <span class="nav-text">Kafka事务</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#生产者事务"><span class="nav-number">1.4.8.1.</span> <span class="nav-text">生产者事务</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#要求"><span class="nav-number">1.4.8.1.1.</span> <span class="nav-text">要求</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#事务操作"><span class="nav-number">1.4.8.1.2.</span> <span class="nav-text">事务操作</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#实战"><span class="nav-number">1.4.8.1.3.</span> <span class="nav-text">实战</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#生产者API-2"><span class="nav-number">1.4.8.1.3.1.</span> <span class="nav-text">生产者API</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#消费者API-2"><span class="nav-number">1.4.8.1.3.2.</span> <span class="nav-text">消费者API</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费生产并存事务（consume-transform-produce）"><span class="nav-number">1.4.8.2.</span> <span class="nav-text">消费生产并存事务（consume-transform-produce）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#要求-1"><span class="nav-number">1.4.8.2.1.</span> <span class="nav-text">要求</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#实战-1"><span class="nav-number">1.4.8.2.2.</span> <span class="nav-text">实战</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Kafka-Streaming"><span class="nav-number">2.</span> <span class="nav-text">Kafka Streaming</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、什么是批处理和流处理？"><span class="nav-number">2.1.</span> <span class="nav-text">一、什么是批处理和流处理？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#批处理-Batch-Processing"><span class="nav-number">2.1.1.</span> <span class="nav-text">批处理 Batch Processing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流处理-Stream-Processing"><span class="nav-number">2.1.2.</span> <span class="nav-text">流处理 Stream Processing</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、Kafka-Straming概述"><span class="nav-number">2.2.</span> <span class="nav-text">二、Kafka Straming概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#特点"><span class="nav-number">2.2.1.</span> <span class="nav-text">特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核心概念-1"><span class="nav-number">2.2.2.</span> <span class="nav-text">核心概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#架构篇"><span class="nav-number">2.2.3.</span> <span class="nav-text">架构篇</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#架构-1"><span class="nav-number">2.2.4.</span> <span class="nav-text">架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#任务的并行度"><span class="nav-number">2.2.4.1.</span> <span class="nav-text">任务的并行度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#容错"><span class="nav-number">2.2.4.2.</span> <span class="nav-text">容错</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、实战操作"><span class="nav-number">2.3.</span> <span class="nav-text">三、实战操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#low-level"><span class="nav-number">2.3.1.</span> <span class="nav-text">low-level</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#maven依赖"><span class="nav-number">2.3.1.1.</span> <span class="nav-text">maven依赖</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#应用"><span class="nav-number">2.3.1.2.</span> <span class="nav-text">应用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建输入和输出Topic"><span class="nav-number">2.3.1.3.</span> <span class="nav-text">创建输入和输出Topic</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#生产者-1"><span class="nav-number">2.3.1.4.</span> <span class="nav-text">生产者</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者-1"><span class="nav-number">2.3.1.5.</span> <span class="nav-text">消费者</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分析原因"><span class="nav-number">2.3.1.6.</span> <span class="nav-text">分析原因</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#状态管理"><span class="nav-number">2.3.1.7.</span> <span class="nav-text">状态管理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#流处理应用的代码（local-state-store）"><span class="nav-number">2.3.1.7.1.</span> <span class="nav-text">流处理应用的代码（local state store）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#自定义处理器代码"><span class="nav-number">2.3.1.7.2.</span> <span class="nav-text">自定义处理器代码</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Remote-State-Store"><span class="nav-number">2.3.1.7.3.</span> <span class="nav-text">Remote State Store</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#high-level"><span class="nav-number">2.3.2.</span> <span class="nav-text">high-level</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Maven依赖-1"><span class="nav-number">2.3.2.1.</span> <span class="nav-text">Maven依赖</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#应用-1"><span class="nav-number">2.3.2.2.</span> <span class="nav-text">应用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分析拓扑运行过程"><span class="nav-number">2.3.2.3.</span> <span class="nav-text">分析拓扑运行过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#操作算子"><span class="nav-number">2.3.2.4.</span> <span class="nav-text">操作算子</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#无状态的操作算子-stateless"><span class="nav-number">2.3.2.4.1.</span> <span class="nav-text">无状态的操作算子(stateless)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#有状态的操作算子-stateful"><span class="nav-number">2.3.2.4.2.</span> <span class="nav-text">有状态的操作算子(stateful)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Window"><span class="nav-number">2.3.2.5.</span> <span class="nav-text">Window</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">骚白</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">骚白</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
